import requests
from bs4 import BeautifulSoup
from datetime import datetime
from save_to_firestore import save_job_posting

# âœ… í¬ë¡¤ë§í•  URL ë° í—¤ë” ì„¤ì •
BASE_URL = "https://www.saramin.co.kr"
JOB_LIST_URL = f"{BASE_URL}/zf_user/jobs/list/job-category?page=1&cat_kewd=403"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# âœ… í•˜ë“œì½”ë”©ëœ ìê¸°ì†Œê°œì„œ ë¬¸í•­ ë¦¬ìŠ¤íŠ¸
SELF_INTRO_QUESTIONS = [
    "1. ì´ ë¶€ë¬¸ì— ì§€ì›í•œ ë™ê¸°ë¥¼ ê¸°ìˆ í•´ ì£¼ì‹­ì‹œì˜¤.",
    "2. ì´ ì§ë¬´ì™€ ê´€ë ¨ëœ ê²½í—˜ì„ ë³¸ì¸ì˜ ì—­í• ê³¼ ì„±ê³¼ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ìˆ í•´ ì£¼ì‹­ì‹œì˜¤.",
    "3. ë‚˜ì™€ ëŒ€ë‹¤ìˆ˜ì˜ ì˜ê²¬ì´ ë‹¤ë¥¸ ê²½ìš°, ë³¸ì¸ì´ ëŒ€ì²˜í–ˆë˜ ê²½í—˜ê³¼ ê·¸ë¡œë¶€í„° ì–»ì€ êµí›ˆì„ ê¸°ìˆ í•´ ì£¼ì‹­ì‹œì˜¤."
]

def extract_job_details(job_url):
    """ê° ì±„ìš© ê³µê³  ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì •ë³´ í¬ë¡¤ë§"""
    response = requests.get(job_url, headers=HEADERS)

    if response.status_code != 200:
        print(f"âŒ ìƒì„¸ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
        return {
            "jobDescription": "í¬ì§€ì…˜ ìƒì„¸ ì—†ìŒ",
            "jobType": "ì •ê·œì§",
            "preferredQualifications": "ìš°ëŒ€ì‚¬í•­ ì—†ìŒ",
            "qualifications": "ìê²© ìš”ê±´ ì—†ìŒ",
            "deadline": "ë§ˆê°ì¼ ì •ë³´ ì—†ìŒ"
        }

    soup = BeautifulSoup(response.text, "html.parser")

    # âœ… ê³µê³  ì¹´ë“œì—ì„œ ì§ì ‘ ì •ë³´ ì¶”ì¶œ
    card_element = soup.select_one(".card_cont.wrap_recruit_view")
    
    deadline = card_element["data-closing-date"] if card_element and "data-closing-date" in card_element.attrs else "ë§ˆê°ì¼ ì •ë³´ ì—†ìŒ"
    job_title = card_element["data-recruit-title"] if card_element and "data-recruit-title" in card_element.attrs else "ê³µê³  ì œëª© ì—†ìŒ"

    # âœ… ê·¼ë¬´ í˜•íƒœ (ì •ê·œì§ ë“±)
    job_type_element = soup.select_one(".section_basic_view .wrap_summary_job .list_summary .type")
    job_type = job_type_element.get_text(strip=True) if job_type_element else "ì •ê·œì§"

    # âœ… ê²½ë ¥ ìš”ê±´
    qualifications_element = soup.select_one(".section_basic_view .wrap_summary_job .list_summary .experience")
    qualifications = qualifications_element.get_text(strip=True).replace("\xa0", " ") if qualifications_element else "ìê²© ìš”ê±´ ì—†ìŒ"

    # âœ… í•™ë ¥ ìš”ê±´
    preferred_qualifications_element = soup.select_one(".section_basic_view .wrap_summary_job .list_summary .education")
    preferred_qualifications = preferred_qualifications_element.get_text(strip=True).replace("\xa0", " ") if preferred_qualifications_element else "ìš°ëŒ€ì‚¬í•­ ì—†ìŒ"

    # âœ… ìƒì„¸ ì„¤ëª… (iframe í¬ë¡¤ë§)
    job_description = "í¬ì§€ì…˜ ìƒì„¸ ì—†ìŒ"
    iframe_element = soup.select_one("iframe.recruit_detail_iframe")
    
    if iframe_element:
        iframe_src = iframe_element.get("data-src") or iframe_element.get("src")
        if iframe_src:
            iframe_url = f"{BASE_URL}{iframe_src}"
            iframe_response = requests.get(iframe_url, headers=HEADERS)
            if iframe_response.status_code == 200:
                iframe_soup = BeautifulSoup(iframe_response.text, "html.parser")
                detail_view = iframe_soup.select_one(".cont_detail_view")
                if detail_view:
                    job_description = detail_view.get_text(strip=True) or "í¬ì§€ì…˜ ìƒì„¸ ì—†ìŒ"

    return {
        "job": job_title,
        "jobDescription": job_description,
        "jobType": job_type,
        "preferredQualifications": preferred_qualifications,
        "qualifications": qualifications,
        "deadline": deadline
    }

def crawl_job_list():
    """1ì°¨ í¬ë¡¤ë§: ì±„ìš© ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ URL ìˆ˜ì§‘"""
    print("ğŸ” ì±„ìš© ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹œì‘...")
    response = requests.get(JOB_LIST_URL, headers=HEADERS)

    if response.status_code != 200:
        print(f"âŒ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    job_elements = soup.select(".list_item")

    job_list = []
    
    for job in job_elements[:10]:  # ìµœëŒ€ 10ê°œ í¬ë¡¤ë§ (í™•ì¥ ê°€ëŠ¥)
        title_element = job.select_one(".job_tit a")
        company_element = job.select_one(".company_nm a")
        link_element = title_element["href"] if title_element else None

        if company_element and link_element:
            job_url = f"{BASE_URL}{link_element}"
            print(f"ğŸ“Œ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘: {job_url}")

            # 2ì°¨ í¬ë¡¤ë§: ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
            job_details = extract_job_details(job_url)

            job_info = {
                "URL": job_url,
                "company": company_element.get_text(strip=True),
                "createdAt": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"),
                "deadline": job_details["deadline"],
                "id": None,
                "isApplied": False,
                "job": job_details["job"],
                "jobDescription": job_details["jobDescription"],
                "jobType": job_details["jobType"],
                "preferredQualifications": job_details["preferredQualifications"],
                "qualifications": job_details["qualifications"],
                "questions": SELF_INTRO_QUESTIONS
            }
            job_list.append(job_info)

    return job_list

if __name__ == "__main__":
    jobs = crawl_job_list()
    
    if jobs:
        print(f"ğŸ“‚ Firestore ì €ì¥ ì‹œì‘ (ì´ {len(jobs)}ê°œ ê³µê³ )")
        for job in jobs:
            print("ğŸ” í¬ë¡¤ë§ëœ ë°ì´í„°:", job)  # í¬ë¡¤ë§ ë°ì´í„° í™•ì¸
            save_job_posting(job)
