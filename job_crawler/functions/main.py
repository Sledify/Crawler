import requests
from bs4 import BeautifulSoup
from datetime import datetime
from save_to_firestore import save_job_posting

# âœ… í¬ë¡¤ë§í•  URL ë° í—¤ë” ì„¤ì •
URL = "https://www.saramin.co.kr/zf_user/jobs/list/job-category?page=1&cat_kewd=403"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# âœ… í•˜ë“œì½”ë”©ëœ ìê¸°ì†Œê°œì„œ ë¬¸í•­ ë¦¬ìŠ¤íŠ¸
SELF_INTRO_QUESTIONS = [
    "1. ì´ ë¶€ë¬¸ì— ì§€ì›í•œ ë™ê¸°ë¥¼ ê¸°ìˆ í•´ ì£¼ì‹­ì‹œì˜¤.",
    "2. ì´ ì§ë¬´ì™€ ê´€ë ¨ëœ ê²½í—˜ì„ ë³¸ì¸ì˜ ì—­í• ê³¼ ì„±ê³¼ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ìˆ í•´ ì£¼ì‹­ì‹œì˜¤.",
    "3. ë‚˜ì™€ ëŒ€ë‹¤ìˆ˜ì˜ ì˜ê²¬ì´ ë‹¤ë¥¸ ê²½ìš°, ë³¸ì¸ì´ ëŒ€ì²˜í–ˆë˜ ê²½í—˜ê³¼ ê·¸ë¡œë¶€í„° ì–»ì€ êµí›ˆì„ ê¸°ìˆ í•´ ì£¼ì‹­ì‹œì˜¤."
]

def crawl_jobs():
    print("ğŸ” í¬ë¡¤ë§ ì‹œì‘...")
    response = requests.get(URL, headers=HEADERS)

    if response.status_code != 200:
        print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    job_elements = soup.select(".list_item")

    job_list = []
    
    for job in job_elements[:10]:  
        title_element = job.select_one(".job_tit a")
        company_element = job.select_one(".company_nm a")
        link_element = title_element["href"] if title_element else None

        if title_element and company_element and link_element:
            job_info = {
                "URL": f"https://www.saramin.co.kr{link_element}",  # âœ… ê¸°ì¡´ 'link' â†’ 'URL'ë¡œ ë³€ê²½
                "company": company_element.get_text(strip=True),
                "createdAt": datetime.utcnow(),  # âœ… í˜„ì¬ ì‹œê°„ ì €ì¥ (UTC ê¸°ì¤€)
                "deadline": None,  # âœ… ë§ˆê°ì¼ ì •ë³´ ì—†ìŒ (í•„ìš” ì‹œ ì¶”ê°€ í¬ë¡¤ë§)
                "id": None,  # âœ… Firestoreì—ì„œ ìë™ ìƒì„±
                "isApplied": False,  # âœ… ê¸°ë³¸ê°’ False
                "job": title_element.get_text(strip=True),  # âœ… ê¸°ì¡´ 'title' â†’ 'job'ë¡œ ë³€ê²½
                "jobDescription": "í¬ì§€ì…˜ ìƒì„¸ ì—†ìŒ",  # âœ… ê¸°ë³¸ ê°’ ì„¤ì • (ì¶”í›„ í¬ë¡¤ë§ ê°€ëŠ¥)
                "jobType": "ì •ê·œì§",  # âœ… ê¸°ë³¸ ê°’ ì„¤ì • (í•„ìš” ì‹œ í¬ë¡¤ë§)
                "preferredQualifications": "ìš°ëŒ€ì‚¬í•­ ì—†ìŒ",  # âœ… ê¸°ë³¸ ê°’ ì„¤ì • (í•„ìš” ì‹œ í¬ë¡¤ë§)
                "qualifications": "ìê²© ìš”ê±´ ì—†ìŒ",  # âœ… ê¸°ë³¸ ê°’ ì„¤ì • (í•„ìš” ì‹œ í¬ë¡¤ë§)
                "questions": SELF_INTRO_QUESTIONS  # âœ… ìê¸°ì†Œê°œì„œ ë¬¸í•­ ì¶”ê°€
            }
            job_list.append(job_info)

    return job_list

if __name__ == "__main__":
    jobs = crawl_jobs()
    
    if jobs:
        print(f"ğŸ“‚ Firestore ì €ì¥ ì‹œì‘ (ì´ {len(jobs)}ê°œ ê³µê³ )")
        for job in jobs:
            print("ğŸ” í¬ë¡¤ë§ëœ ë°ì´í„°:", job)  # í¬ë¡¤ë§ ë°ì´í„° í™•ì¸
            save_job_posting(job)
